# -*- coding: utf-8 -*-
"""melanoma new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LkUR0FiNcVPfi4Lahqb3EsNEXM84MTHL
"""

# All-in-One Melanoma CGAN + ResNet50 Classifier (balanced + focal loss + risk fusion)
# Designed for local execution (VS Code)
import os
import numpy as np
import pandas as pd
import random
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.utils import save_image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# ---------------------------
# 0. Quick config (edit as needed)
# ---------------------------
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", DEVICE)

DATA_DIR = "./data/ISIC2018_Task3_Training_Input/ISIC2018_Task3_Training_Input"
LABELS_CSV = "./data/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv"
OUT_DIR = "./melanoma_cgan_project_v2"
SYN_DIR = os.path.join(OUT_DIR, "synthetic_images")
RESULTS_DIR = os.path.join(OUT_DIR, "results")
os.makedirs(SYN_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

# Image sizes
IMG_SIZE_CGAN = 128
IMG_SIZE_CLS = 224

# Model / training hyperparams (tune as needed)
LATENT_DIM = 100
COND_DIM = 3   # uv_risk, genetic_risk, class_label (0 or 1)
BATCH_SIZE = 32
EPOCHS_CGAN = 50        # reduce for quick runs; increase for quality
EPOCHS_CLS = 30
LR_CGAN = 2e-4
LR_CLS = 1e-4
BETA1 = 0.5
N_SYNTHETIC_MAX = 10000  # safety cap in generation
SAMPLE_SHOW = 6

# ---------------------------
# 1. Load labels and compute imbalance
# ---------------------------
df_labels = pd.read_csv(LABELS_CSV)

# robust column handling
if 'MEL' in df_labels.columns:
    df_labels['is_melanoma'] = (df_labels['MEL'] == 1.0).astype(int)
elif 'melanoma' in df_labels.columns:
    df_labels['is_melanoma'] = (df_labels['melanoma'] == 1.0).astype(int)
else:
    raise ValueError("Labels CSV missing 'MEL' or 'melanoma' column.")

if 'image' not in df_labels.columns:
    raise ValueError("Labels CSV missing 'image' column.")

df_labels['image'] = df_labels['image'].astype(str)
n_mel = int(df_labels['is_melanoma'].sum())
n_nonmel = len(df_labels) - n_mel
print(f"Real counts -> Melanoma: {n_mel}, Non-melanoma: {n_nonmel}")

# ---------------------------
# 2. Transforms
# ---------------------------
cgan_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CGAN, IMG_SIZE_CGAN)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

cls_train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CLS, IMG_SIZE_CLS)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

cls_val_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CLS, IMG_SIZE_CLS)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

# ---------------------------
# 3. Dataset classes (fixed)
# ---------------------------
class MelanomaCGANDataset(Dataset):
    """Real melanoma images used to train GAN (we can train on both classes optionally).
       Here we accept ids (image names without extension) and optional class labels per id.
    """
    def __init__(self, ids, img_dir, transform=None, labels_map=None):
        self.ids = [str(i) for i in ids]
        self.img_dir = img_dir
        self.transform = transform
        # risk priors
        self.uv_risks = np.random.beta(2, 5, size=len(self.ids))
        self.genetic_risks = np.random.beta(3, 4, size=len(self.ids))
        # labels_map: dict image_id -> 0/1 if available
        self.labels_map = labels_map or {}

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]
        img_path = os.path.join(self.img_dir, f"{img_id}.jpg")
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"Image {img_path} not found.")
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img = self.transform(img)
        uv = float(self.uv_risks[idx])
        gen = float(self.genetic_risks[idx])
        label = int(self.labels_map.get(img_id, 1))  # default 1 if not provided
        cond = torch.tensor([uv, gen, float(label)], dtype=torch.float32)
        return img, cond

class CombinedDataset(Dataset):
    """Combined dataset of real & synthetic images for classifier training.
       Real ids: 'imagename' (no extension). Synthetic ids: 'syn_xxxxx.png' filenames.
    """
    def __init__(self, ids, img_dir, syn_df, transform=None):
        self.ids = [str(i) for i in ids]
        self.img_dir = img_dir
        self.syn_df = syn_df.copy() if syn_df is not None else pd.DataFrame(columns=['filename','uv_risk','genetic_risk','class'])
        self.transform = transform
        # consistent risk assignment for real images
        real_ids = [i for i in self.ids if not i.startswith('syn_')]
        self.real_risks = {rid: (float(np.random.beta(2,5)), float(np.random.beta(3,4))) for rid in real_ids}

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        item = self.ids[idx]
        if item.startswith('syn_'):
            img_path = os.path.join(SYN_DIR, item)
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"Expected synthetic image {img_path} not found.")
            img = Image.open(img_path).convert("RGB")
            row = self.syn_df.loc[self.syn_df['filename'] == item]
            if row.empty:
                uv, gen, label = np.random.beta(2,5), np.random.beta(3,4), 1
            else:
                row = row.iloc[0]
                uv, gen, label = float(row['uv_risk']), float(row['genetic_risk']), int(row['class'])
        else:
            img_path = os.path.join(self.img_dir, f"{item}.jpg")
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"Expected real image {img_path} not found.")
            img = Image.open(img_path).convert("RGB")
            uv, gen = self.real_risks.get(item, (np.random.beta(2,5), np.random.beta(3,4)))
            row = df_labels.loc[df_labels['image'] == item]
            label = int(row['is_melanoma'].iloc[0]) if not row.empty else 0

        if self.transform:
            img = self.transform(img)

        risks = torch.tensor([uv, gen], dtype=torch.float32)
        label_tensor = torch.tensor([label], dtype=torch.float32)
        return img, risks, label_tensor

# ---------------------------
# 4. CGAN (conditional on uv, genetic, class_label)
# ---------------------------
def weights_init(m):
    name = m.__class__.__name__
    if 'Conv' in name:
        try:
            nn.init.normal_(m.weight.data, 0.0, 0.02)
        except Exception:
            pass
    elif 'BatchNorm' in name:
        try:
            nn.init.normal_(m.weight.data, 1.0, 0.02)
            nn.init.constant_(m.bias.data, 0)
        except Exception:
            pass

class Generator(nn.Module):
    def __init__(self, latent_dim=LATENT_DIM, cond_dim=COND_DIM):
        super().__init__()
        self.latent_dim = latent_dim
        self.cond_dim = cond_dim
        input_dim = latent_dim + cond_dim
        self.main = nn.Sequential(
            # input: (input_dim) -> project to a small spatial map
            nn.ConvTranspose2d(input_dim, 512, 4, 1, 0, bias=False),  # -> (512,4,4)
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # -> (256,8,8)
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # -> (128,16,16)
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),   # -> (64,32,32)
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),    # -> (32,64,64)
            nn.BatchNorm2d(32),
            nn.ReLU(True),

            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias=False),     # -> (3,128,128)
            nn.Tanh()
        )

    def forward(self, noise, cond):
        # noise: (B, latent_dim), cond: (B, cond_dim)
        x = torch.cat([noise, cond], dim=1)               # (B, latent+cond)
        x = x.view(x.size(0), -1, 1, 1)                   # (B, channels,1,1)
        return self.main(x)

class Discriminator(nn.Module):
    def __init__(self, cond_dim=COND_DIM):
        super().__init__()
        self.cond_dim = cond_dim
        # Image pathway
        self.img_path = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),   # (64,64,64)
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 4, 2, 1, bias=False), # (128,32,32)
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1, bias=False), # (256,16,16)
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, 4, 2, 1, bias=False), # (512,8,8)
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 512, 4, 2, 1, bias=False), # (512,4,4)
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
        )
        # final conv expects channels = 512 + cond_dim
        self.final = nn.Conv2d(512 + cond_dim, 1, 4, 1, 0, bias=False)  # -> (1,1,1)

    def forward(self, img, cond):
        # img: (B,3,128,128); cond: (B,cond_dim)
        f = self.img_path(img)  # (B,512,4,4)
        # expand cond to spatial map
        cond_map = cond.view(cond.size(0), -1, 1, 1).expand(-1, -1, f.size(2), f.size(3))
        x = torch.cat([f, cond_map], dim=1)
        out = self.final(x)     # (B,1,1,1)
        return out.view(-1)

# ---------------------------
# 9. Classifier: ResNet50 backbone + risk fusion
# ---------------------------
class RiskResNet50(nn.Module):
    def __init__(self, dropout=0.5, risk_emb_dim=16):
        super().__init__()
        self.backbone = models.resnet50(pretrained=True)
        # replace fc with identity, we'll handle classifier head
        in_feats = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        # risk embedding
        self.risk_processor = nn.Sequential(
            nn.Linear(2, risk_emb_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        # classifier head combines image features + risk features
        self.classifier = nn.Sequential(
            nn.Linear(in_feats + risk_emb_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 1)  # single logit
        )

    def forward(self, img, risks):
        img_feat = self.backbone(img)               # (B, in_feats)
        risk_feat = self.risk_processor(risks)      # (B, risk_emb_dim)
        combined = torch.cat([img_feat, risk_feat], dim=1)
        logits = self.classifier(combined)
        return logits

# ---------------------------
# 10. Loss: Focal Loss (binary) + optimizer + scheduler
# ---------------------------
class BinaryFocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        self.bce = nn.BCEWithLogitsLoss(reduction='none')

    def forward(self, logits, targets):
        # logits: (B,1) or (B,)
        logits = logits.view(-1)
        targets = targets.view(-1)
        bce_loss = self.bce(logits, targets)
        probas = torch.sigmoid(logits)
        p_t = probas * targets + (1 - probas) * (1 - targets)
        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
        focal_loss = alpha_t * (1 - p_t) ** self.gamma * bce_loss
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

# ---------------------------
# 11. Train/Eval Functions
# ---------------------------
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    total_loss = 0.0
    for imgs, risks, labels in tqdm(loader, desc="Train batches"):
        imgs = imgs.to(DEVICE)
        risks = risks.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        logits = model(imgs, risks)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def eval_model(model, loader, criterion):
    model.eval()
    total_loss = 0.0
    preds = []
    trues = []
    with torch.no_grad():
        for imgs, risks, labels in loader:
            imgs = imgs.to(DEVICE)
            risks = risks.to(DEVICE)
            labels = labels.to(DEVICE)
            logits = model(imgs, risks)
            loss = criterion(logits, labels)
            total_loss += loss.item()
            prob = torch.sigmoid(logits).cpu().numpy().flatten()
            preds.extend(prob.tolist())
            trues.extend(labels.cpu().numpy().flatten().tolist())
    return total_loss / len(loader), np.array(preds), np.array(trues)
    
# ---------------------------
# 13. Grad-CAM (simple implementation for inspection)
# ---------------------------
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.model.eval()
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        # register hooks
        def forward_hook(module, inp, out):
            self.activations = out.detach()
        def backward_hook(module, grad_in, grad_out):
            self.gradients = grad_out[0].detach()
        target_layer.register_forward_hook(forward_hook)
        target_layer.register_backward_hook(backward_hook)

    def __call__(self, img_tensor, risk_tensor, class_idx=1):
        self.model.zero_grad()
        logits = self.model(img_tensor, risk_tensor)
        score = logits[:, 0]  # single logit
        score.backward(retain_graph=True)
        # pooled gradients
        pooled = torch.mean(self.gradients, dim=(2,3), keepdim=True)
        weighted = self.activations * pooled
        heatmap = torch.mean(weighted, dim=1).squeeze()
        heatmap = torch.relu(heatmap)
        heatmap = heatmap.cpu().numpy()
        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
        return heatmap

def overlay_heatmap(img_np, heatmap, alpha=0.4):
    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))
    heat_uint8 = np.uint8(255 * heatmap_resized)
    heat_color = cv2.applyColorMap(heat_uint8, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted((img_np*255).astype(np.uint8), 1 - alpha, heat_color, alpha, 0)
    return overlay

# ====================================================================
# SCRIPT EXECUTION STARTS HERE
# ====================================================================
# -*- coding: utf-8 -*-
"""melanoma new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LkUR0FiNcVPfi4Lahqb3EsNEXM84MTHL
"""

# All-in-One Melanoma CGAN + ResNet50 Classifier (balanced + focal loss + risk fusion)
# Designed for local execution (VS Code)
import os
import numpy as np
import pandas as pd
import random
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt
import seaborn as sns
import cv2

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.utils import save_image
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# ---------------------------
# 0. Quick config (edit as needed)
# ---------------------------
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", DEVICE)

DATA_DIR = "./data/ISIC2018_Task3_Training_Input"
LABELS_CSV = "./data/ISIC2018_Task3_Training_GroundTruth/ISIC2018_Task3_Training_GroundTruth.csv"
OUT_DIR = "./melanoma_cgan_project_v2"
SYN_DIR = os.path.join(OUT_DIR, "synthetic_images")
RESULTS_DIR = os.path.join(OUT_DIR, "results")
os.makedirs(SYN_DIR, exist_ok=True)
os.makedirs(RESULTS_DIR, exist_ok=True)

# Image sizes
IMG_SIZE_CGAN = 128
IMG_SIZE_CLS = 224

# Model / training hyperparams (tune as needed)
LATENT_DIM = 100
COND_DIM = 3   # uv_risk, genetic_risk, class_label (0 or 1)
BATCH_SIZE = 32
EPOCHS_CGAN = 50        # reduce for quick runs; increase for quality
EPOCHS_CLS = 30
LR_CGAN = 2e-4
LR_CLS = 1e-4
BETA1 = 0.5
N_SYNTHETIC_MAX = 10000  # safety cap in generation
SAMPLE_SHOW = 6

# ---------------------------
# 1. Load labels and compute imbalance
# ---------------------------
df_labels = pd.read_csv(LABELS_CSV)

# robust column handling
if 'MEL' in df_labels.columns:
    df_labels['is_melanoma'] = (df_labels['MEL'] == 1.0).astype(int)
elif 'melanoma' in df_labels.columns:
    df_labels['is_melanoma'] = (df_labels['melanoma'] == 1.0).astype(int)
else:
    raise ValueError("Labels CSV missing 'MEL' or 'melanoma' column.")

if 'image' not in df_labels.columns:
    raise ValueError("Labels CSV missing 'image' column.")

df_labels['image'] = df_labels['image'].astype(str)
n_mel = int(df_labels['is_melanoma'].sum())
n_nonmel = len(df_labels) - n_mel
print(f"Real counts -> Melanoma: {n_mel}, Non-melanoma: {n_nonmel}")

# ---------------------------
# 2. Transforms
# ---------------------------
cgan_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CGAN, IMG_SIZE_CGAN)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

cls_train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CLS, IMG_SIZE_CLS)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomVerticalFlip(),
    transforms.RandomRotation(20),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.02),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

cls_val_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE_CLS, IMG_SIZE_CLS)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),
])

# ---------------------------
# 3. Dataset classes (fixed)
# ---------------------------
class MelanomaCGANDataset(Dataset):
    """Real melanoma images used to train GAN (we can train on both classes optionally).
       Here we accept ids (image names without extension) and optional class labels per id.
    """
    def __init__(self, ids, img_dir, transform=None, labels_map=None):
        self.ids = [str(i) for i in ids]
        self.img_dir = img_dir
        self.transform = transform
        # risk priors
        self.uv_risks = np.random.beta(2, 5, size=len(self.ids))
        self.genetic_risks = np.random.beta(3, 4, size=len(self.ids))
        # labels_map: dict image_id -> 0/1 if available
        self.labels_map = labels_map or {}

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        img_id = self.ids[idx]
        img_path = os.path.join(self.img_dir, f"{img_id}.jpg")
        if not os.path.exists(img_path):
            raise FileNotFoundError(f"Image {img_path} not found.")
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img = self.transform(img)
        uv = float(self.uv_risks[idx])
        gen = float(self.genetic_risks[idx])
        label = int(self.labels_map.get(img_id, 1))  # default 1 if not provided
        cond = torch.tensor([uv, gen, float(label)], dtype=torch.float32)
        return img, cond

class CombinedDataset(Dataset):
    """Combined dataset of real & synthetic images for classifier training.
       Real ids: 'imagename' (no extension). Synthetic ids: 'syn_xxxxx.png' filenames.
    """
    def __init__(self, ids, img_dir, syn_df, transform=None):
        self.ids = [str(i) for i in ids]
        self.img_dir = img_dir
        self.syn_df = syn_df.copy() if syn_df is not None else pd.DataFrame(columns=['filename','uv_risk','genetic_risk','class'])
        self.transform = transform
        # consistent risk assignment for real images
        real_ids = [i for i in self.ids if not i.startswith('syn_')]
        self.real_risks = {rid: (float(np.random.beta(2,5)), float(np.random.beta(3,4))) for rid in real_ids}

    def __len__(self):
        return len(self.ids)

    def __getitem__(self, idx):
        item = self.ids[idx]
        if item.startswith('syn_'):
            img_path = os.path.join(SYN_DIR, item)
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"Expected synthetic image {img_path} not found.")
            img = Image.open(img_path).convert("RGB")
            row = self.syn_df.loc[self.syn_df['filename'] == item]
            if row.empty:
                uv, gen, label = np.random.beta(2,5), np.random.beta(3,4), 1
            else:
                row = row.iloc[0]
                uv, gen, label = float(row['uv_risk']), float(row['genetic_risk']), int(row['class'])
        else:
            img_path = os.path.join(self.img_dir, f"{item}.jpg")
            if not os.path.exists(img_path):
                raise FileNotFoundError(f"Expected real image {img_path} not found.")
            img = Image.open(img_path).convert("RGB")
            uv, gen = self.real_risks.get(item, (np.random.beta(2,5), np.random.beta(3,4)))
            row = df_labels.loc[df_labels['image'] == item]
            label = int(row['is_melanoma'].iloc[0]) if not row.empty else 0

        if self.transform:
            img = self.transform(img)

        risks = torch.tensor([uv, gen], dtype=torch.float32)
        label_tensor = torch.tensor([label], dtype=torch.float32)
        return img, risks, label_tensor

# ---------------------------
# 4. CGAN (conditional on uv, genetic, class_label)
# ---------------------------
def weights_init(m):
    name = m.__class__.__name__
    if 'Conv' in name:
        try:
            nn.init.normal_(m.weight.data, 0.0, 0.02)
        except Exception:
            pass
    elif 'BatchNorm' in name:
        try:
            nn.init.normal_(m.weight.data, 1.0, 0.02)
            nn.init.constant_(m.bias.data, 0)
        except Exception:
            pass

class Generator(nn.Module):
    def __init__(self, latent_dim=LATENT_DIM, cond_dim=COND_DIM):
        super().__init__()
        self.latent_dim = latent_dim
        self.cond_dim = cond_dim
        input_dim = latent_dim + cond_dim
        self.main = nn.Sequential(
            # input: (input_dim) -> project to a small spatial map
            nn.ConvTranspose2d(input_dim, 512, 4, 1, 0, bias=False),  # -> (512,4,4)
            nn.BatchNorm2d(512),
            nn.ReLU(True),

            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias=False),  # -> (256,8,8)
            nn.BatchNorm2d(256),
            nn.ReLU(True),

            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),  # -> (128,16,16)
            nn.BatchNorm2d(128),
            nn.ReLU(True),

            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),   # -> (64,32,32)
            nn.BatchNorm2d(64),
            nn.ReLU(True),

            nn.ConvTranspose2d(64, 32, 4, 2, 1, bias=False),    # -> (32,64,64)
            nn.BatchNorm2d(32),
            nn.ReLU(True),

            nn.ConvTranspose2d(32, 3, 4, 2, 1, bias=False),     # -> (3,128,128)
            nn.Tanh()
        )

    def forward(self, noise, cond):
        # noise: (B, latent_dim), cond: (B, cond_dim)
        x = torch.cat([noise, cond], dim=1)               # (B, latent+cond)
        x = x.view(x.size(0), -1, 1, 1)                   # (B, channels,1,1)
        return self.main(x)

class Discriminator(nn.Module):
    def __init__(self, cond_dim=COND_DIM):
        super().__init__()
        self.cond_dim = cond_dim
        # Image pathway
        self.img_path = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias=False),   # (64,64,64)
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(64, 128, 4, 2, 1, bias=False), # (128,32,32)
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(128, 256, 4, 2, 1, bias=False), # (256,16,16)
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(256, 512, 4, 2, 1, bias=False), # (512,8,8)
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),

            nn.Conv2d(512, 512, 4, 2, 1, bias=False), # (512,4,4)
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
        )
        # final conv expects channels = 512 + cond_dim
        self.final = nn.Conv2d(512 + cond_dim, 1, 4, 1, 0, bias=False)  # -> (1,1,1)

    def forward(self, img, cond):
        # img: (B,3,128,128); cond: (B,cond_dim)
        f = self.img_path(img)  # (B,512,4,4)
        # expand cond to spatial map
        cond_map = cond.view(cond.size(0), -1, 1, 1).expand(-1, -1, f.size(2), f.size(3))
        x = torch.cat([f, cond_map], dim=1)
        out = self.final(x)     # (B,1,1,1)
        return out.view(-1)

# ---------------------------
# 9. Classifier: ResNet50 backbone + risk fusion
# ---------------------------
class RiskResNet50(nn.Module):
    def __init__(self, dropout=0.5, risk_emb_dim=16):
        super().__init__()
        self.backbone = models.resnet50(weights='IMAGENET1K_V1')
        # replace fc with identity, we'll handle classifier head
        in_feats = self.backbone.fc.in_features
        self.backbone.fc = nn.Identity()
        # risk embedding
        self.risk_processor = nn.Sequential(
            nn.Linear(2, risk_emb_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        # classifier head combines image features + risk features
        self.classifier = nn.Sequential(
            nn.Linear(in_feats + risk_emb_dim, 512),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(512, 1)  # single logit
        )

    def forward(self, img, risks):
        img_feat = self.backbone(img)               # (B, in_feats)
        risk_feat = self.risk_processor(risks)      # (B, risk_emb_dim)
        combined = torch.cat([img_feat, risk_feat], dim=1)
        logits = self.classifier(combined)
        return logits

# ---------------------------
# 10. Loss: Focal Loss (binary) + optimizer + scheduler
# ---------------------------
class BinaryFocalLoss(nn.Module):
    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.reduction = reduction
        self.bce = nn.BCEWithLogitsLoss(reduction='none')

    def forward(self, logits, targets):
        # logits: (B,1) or (B,)
        logits = logits.view(-1)
        targets = targets.view(-1)
        bce_loss = self.bce(logits, targets)
        probas = torch.sigmoid(logits)
        p_t = probas * targets + (1 - probas) * (1 - targets)
        alpha_t = self.alpha * targets + (1 - self.alpha) * (1 - targets)
        focal_loss = alpha_t * (1 - p_t) ** self.gamma * bce_loss
        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

# ---------------------------
# 11. Train/Eval Functions
# ---------------------------
def train_epoch(model, loader, criterion, optimizer):
    model.train()
    total_loss = 0.0
    for imgs, risks, labels in tqdm(loader, desc="Train batches"):
        imgs = imgs.to(DEVICE)
        risks = risks.to(DEVICE)
        labels = labels.to(DEVICE)
        optimizer.zero_grad()
        logits = model(imgs, risks)
        loss = criterion(logits, labels)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def eval_model(model, loader, criterion):
    model.eval()
    total_loss = 0.0
    preds = []
    trues = []
    with torch.no_grad():
        for imgs, risks, labels in loader:
            imgs = imgs.to(DEVICE)
            risks = risks.to(DEVICE)
            labels = labels.to(DEVICE)
            logits = model(imgs, risks)
            loss = criterion(logits, labels)
            total_loss += loss.item()
            prob = torch.sigmoid(logits).cpu().numpy().flatten()
            preds.extend(prob.tolist())
            trues.extend(labels.cpu().numpy().flatten().tolist())
    return total_loss / len(loader), np.array(preds), np.array(trues)
    
# ---------------------------
# 13. Grad-CAM (simple implementation for inspection)
# ---------------------------
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.model.eval()
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        # register hooks
        def forward_hook(module, inp, out):
            self.activations = out.detach()
        def backward_hook(module, grad_in, grad_out):
            self.gradients = grad_out[0].detach()
        target_layer.register_forward_hook(forward_hook)
        target_layer.register_backward_hook(backward_hook)

    def __call__(self, img_tensor, risk_tensor, class_idx=1):
        self.model.zero_grad()
        logits = self.model(img_tensor, risk_tensor)
        score = logits[:, 0]  # single logit
        score.backward(retain_graph=True)
        # pooled gradients
        pooled = torch.mean(self.gradients, dim=(2,3), keepdim=True)
        weighted = self.activations * pooled
        heatmap = torch.mean(weighted, dim=1).squeeze()
        heatmap = torch.relu(heatmap)
        heatmap = heatmap.cpu().numpy()
        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)
        return heatmap

def overlay_heatmap(img_np, heatmap, alpha=0.4):
    heatmap_resized = cv2.resize(heatmap, (img_np.shape[1], img_np.shape[0]))
    heat_uint8 = np.uint8(255 * heatmap_resized)
    heat_color = cv2.applyColorMap(heat_uint8, cv2.COLORMAP_JET)
    overlay = cv2.addWeighted((img_np*255).astype(np.uint8), 1 - alpha, heat_color, alpha, 0)
    return overlay

# ====================================================================
# SCRIPT EXECUTION STARTS HERE
# ====================================================================
if __name__ == '__main__':

    # ---------------------------
    # 5. Train CGAN and generate synthetic data
    # ---------------------------
    real_ids = df_labels['image'].values
    labels_map = {row['image']: int(row['is_melanoma']) for _, row in df_labels.iterrows()}
    print("Preparing CGAN dataset...")
    cgan_dataset = MelanomaCGANDataset(real_ids, DATA_DIR, transform=cgan_transform, labels_map=labels_map)
    cgan_loader = DataLoader(cgan_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)

    netG = Generator(latent_dim=LATENT_DIM, cond_dim=COND_DIM).to(DEVICE)
    gen_path = os.path.join(OUT_DIR, "cgan_generator_cond.pth")

    # Check if the generator has already been trained and saved
    if os.path.exists(gen_path):
        print(f"Found existing generator at {gen_path}, loading weights...")
        netG.load_state_dict(torch.load(gen_path, map_location=DEVICE))
        print("Generator weights loaded successfully.")
    
    else:
        # If no saved generator, initialize the Discriminator and train both
        print("No existing generator found. Starting CGAN training...")
        netD = Discriminator(cond_dim=COND_DIM).to(DEVICE)
        netG.apply(weights_init)
        netD.apply(weights_init)

        # Losses + optimizers
        criterion_gan = nn.BCEWithLogitsLoss()
        optimizerD = optim.Adam(netD.parameters(), lr=LR_CGAN, betas=(BETA1, 0.999))
        optimizerG = optim.Adam(netG.parameters(), lr=LR_CGAN, betas=(BETA1, 0.999))

        for epoch in range(1, EPOCHS_CGAN + 1):
            netG.train(); netD.train()
            epoch_d_loss = 0.0; epoch_g_loss = 0.0
            for imgs, cond in tqdm(cgan_loader, desc=f"CGAN Epoch {epoch}/{EPOCHS_CGAN}"):
                imgs = imgs.to(DEVICE)
                cond = cond.to(DEVICE)
                b = imgs.size(0)

                # train D on real
                netD.zero_grad()
                real_labels = torch.ones(b, device=DEVICE)
                out_real = netD(imgs, cond)
                lossD_real = criterion_gan(out_real, real_labels)
                lossD_real.backward()

                # sample noise + cond for fake
                noise = torch.randn(b, LATENT_DIM, device=DEVICE)
                fake_imgs = netG(noise, cond)
                fake_labels = torch.zeros(b, device=DEVICE)
                out_fake = netD(fake_imgs.detach(), cond)
                lossD_fake = criterion_gan(out_fake, fake_labels)
                lossD_fake.backward()
                lossD = (lossD_real + lossD_fake)
                optimizerD.step()

                # train G
                netG.zero_grad()
                out_fake_for_g = netD(fake_imgs, cond)
                lossG = criterion_gan(out_fake_for_g, real_labels)
                lossG.backward()
                optimizerG.step()

                epoch_d_loss += lossD.item()
                epoch_g_loss += lossG.item()

            print(f"Epoch {epoch} | D_loss: {epoch_d_loss/len(cgan_loader):.4f} | G_loss: {epoch_g_loss/len(cgan_loader):.4f}")

        # Save the newly trained generator
        torch.save(netG.state_dict(), gen_path)
        print("Saved generator to", gen_path)

    # ---------------------------
    # 6. Generate synthetic images to balance classes
    # ---------------------------
    target_per_class = max(n_mel, n_nonmel)
    req_mel = max(0, target_per_class - n_mel)
    req_nonmel = max(0, target_per_class - n_nonmel)
    req_mel = min(req_mel, N_SYNTHETIC_MAX)
    req_nonmel = min(req_nonmel, N_SYNTHETIC_MAX)

    print(f"Will generate synthetic -> Melanoma: {req_mel}, Non-melanoma: {req_nonmel}")

    netG.eval()
    synthetic_records = []
    with torch.no_grad():
        def gen_batch(n, class_label):
            out_records = []
            steps = max(1, (n + BATCH_SIZE - 1) // BATCH_SIZE)
            count = 0
            for _ in range(steps):
                cur = min(BATCH_SIZE, n - count)
                if cur <= 0: break
                noise = torch.randn(cur, LATENT_DIM, device=DEVICE)
                uv = np.random.beta(2,5, size=cur).astype(np.float32)
                gen = np.random.beta(3,4, size=cur).astype(np.float32)
                cls = np.full((cur,), float(class_label), dtype=np.float32)
                cond_np = np.stack([uv, gen, cls], axis=1)
                cond = torch.tensor(cond_np, dtype=torch.float32, device=DEVICE)
                fakes = netG(noise, cond).cpu()
                for i in range(cur):
                    fname = f"syn_{class_label}_{count+i:05d}.png"
                    tensor_img = (fakes[i] * 0.5 + 0.5).clamp(0,1)
                    save_image(tensor_img, os.path.join(SYN_DIR, fname))
                    out_records.append({'filename': fname, 'uv_risk': float(uv[i]), 'genetic_risk': float(gen[i]), 'class': int(class_label)})
                count += cur
            return out_records

        if req_mel > 0:
            print("Generating melanoma synthetics ...")
            synthetic_records.extend(gen_batch(req_mel, class_label=1))
        if req_nonmel > 0:
            print("Generating non-melanoma synthetics ...")
            synthetic_records.extend(gen_batch(req_nonmel, class_label=0))

    syn_df = pd.DataFrame(synthetic_records)
    syn_idx_path = os.path.join(OUT_DIR, "synthetic_index.csv")
    syn_df.to_csv(syn_idx_path, index=False)
    print(f"Synthetic images saved: {len(syn_df)} records -> {syn_idx_path}")

    # ---------------------------
    # 7. Visualize generated samples
    # ---------------------------
    if len(syn_df) > 0:
        sample = syn_df.sample(min(SAMPLE_SHOW, len(syn_df)), random_state=42)
        fig, axs = plt.subplots(1, len(sample), figsize=(3*len(sample),3))
        for ax, (_, row) in zip(axs, sample.iterrows()):
            img_path = os.path.join(SYN_DIR, row['filename'])
            img = Image.open(img_path).convert("RGB")
            ax.imshow(img)
            ax.set_title(f"class={row['class']}\nuv={row['uv_risk']:.2f}")
            ax.axis('off')
        plt.suptitle("Sample synthetic images")
        plt.savefig(os.path.join(RESULTS_DIR, "sample_synthetics.png"))
        plt.show()

    # ---------------------------
    # 8. Prepare Combined dataset + splits
    # ---------------------------
    real_ids_list = df_labels['image'].values.astype(str).tolist()
    synthetic_ids_list = syn_df['filename'].values.astype(str).tolist()
    all_ids = np.array(real_ids_list + synthetic_ids_list)

    y_temp = []
    for i in all_ids:
        if i.startswith('syn_'):
            row = syn_df.loc[syn_df['filename'] == i]
            if row.empty: y_temp.append(1)
            else: y_temp.append(int(row.iloc[0]['class']))
        else:
            row = df_labels.loc[df_labels['image'] == i]
            y_temp.append(int(row['is_melanoma'].iloc[0]))

    y_temp = np.array(y_temp)
    print(f"Combined dataset size: {len(all_ids)} -> melanoma count: {int((y_temp==1).sum())}, non-mel: {int((y_temp==0).sum())}")

    train_ids, val_ids, ytrain, yval = train_test_split(all_ids, y_temp, test_size=0.2, random_state=42, stratify=y_temp)
    print(f"Train size: {len(train_ids)} | Val size: {len(val_ids)}")

    train_dataset = CombinedDataset(train_ids, DATA_DIR, syn_df, transform=cls_train_transform)
    val_dataset = CombinedDataset(val_ids, DATA_DIR, syn_df, transform=cls_val_transform)

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)

    # ---------------------------
    # 9. & 10. Classifier and Loss Setup
    # ---------------------------
    model = RiskResNet50().to(DEVICE)
    criterion_cls = BinaryFocalLoss(alpha=0.75, gamma=2.0).to(DEVICE)
    optimizer_cls = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR_CLS)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer_cls, mode='min', factor=0.5, patience=3)

    # ---------------------------
    # 11. Train classifier
    # ---------------------------
    best_val_loss = float('inf')
    for epoch in range(1, EPOCHS_CLS + 1):
        train_loss = train_epoch(model, train_loader, criterion_cls, optimizer_cls)
        val_loss, val_preds, val_trues = eval_model(model, val_loader, criterion_cls)
        scheduler.step(val_loss)
        val_preds_bin = (val_preds > 0.5).astype(int)
        print(f"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}")
        print(classification_report(val_trues, val_preds_bin, target_names=['Non-Mel','Mel'], digits=4))
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save(model.state_dict(), os.path.join(OUT_DIR, "best_resnet50_risk.pth"))
            print("Saved best model.")

    # ---------------------------
    # 12. Final evaluation + confusion matrix
    # ---------------------------
    model.load_state_dict(torch.load(os.path.join(OUT_DIR, "best_resnet50_risk.pth")))
    _, val_preds, val_trues = eval_model(model, val_loader, criterion_cls)
    y_pred = (val_preds > 0.5).astype(int)
    y_true = val_trues.astype(int)

    print("\nFinal Classification Report:")
    print(classification_report(y_true, y_pred, target_names=['Non-Mel','Mel'], digits=4))

    cm = confusion_matrix(y_true, y_pred)
    fig, ax = plt.subplots(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Mel','Mel'], yticklabels=['Non-Mel','Mel'], ax=ax)
    ax.set_xlabel('Predicted'); ax.set_ylabel('True'); ax.set_title('Final Confusion Matrix')
    plt.savefig(os.path.join(RESULTS_DIR, "confusion_matrix_final.png"))
    plt.show()

    # ---------------------------
    # 13. Grad-CAM
    # ---------------------------
    mel_val_indices = [i for i, v in enumerate(y_true) if v == 1]
    if len(mel_val_indices) > 0:
        idx = mel_val_indices[0]
        sample_img, sample_risks, _ = val_dataset[idx]
        inp_img = sample_img.unsqueeze(0).to(DEVICE)
        inp_risks = sample_risks.unsqueeze(0).to(DEVICE)
        target_layer = model.backbone.layer4[-1].conv3
        cam = GradCAM(model, target_layer)
        heatmap = cam(inp_img, inp_risks)
        img_np = sample_img.permute(1,2,0).cpu().numpy()*0.5 + 0.5
        overlay = overlay_heatmap(img_np, heatmap)
        plt.figure(figsize=(8,4))
        plt.subplot(1,2,1); plt.imshow(img_np); plt.title("Original"); plt.axis('off')
        plt.subplot(1,2,2); plt.imshow(overlay); plt.title("Grad-CAM Overlay"); plt.axis('off')
        plt.savefig(os.path.join(RESULTS_DIR, "gradcam_sample.png"))
        plt.show()
    else:
        print("No melanoma sample in validation to show Grad-CAM.")

    print("Done. Results saved in:", RESULTS_DIR)